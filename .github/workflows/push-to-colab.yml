name: Push Notebook to Google Drive (Colab)

on:
  push:
    branches: [main]
    paths:
      - 'notebooks/**'
      - 'data/**'
      - '.github/workflows/push-to-colab.yml'

jobs:
  upload-to-gdrive:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install pydrive2 oauth2client

    - name: Upload to Google Drive
      env:
        GDRIVE_CREDENTIALS_JSON: ${{ secrets.GDRIVE_CREDENTIALS_JSON }}
        TARGET_FOLDER_ID: "1Q4h2xGEZTN-GNUCUc6KIva7-EYyl9ch9"
      run: |
        echo "$GDRIVE_CREDENTIALS_JSON" > creds.json

        python <<EOF
        from pydrive2.auth import GoogleAuth
        from pydrive2.drive import GoogleDrive
        from oauth2client.service_account import ServiceAccountCredentials
        import pkg_resources
        import os

        # Auth
        gauth = GoogleAuth()
        # NOTE: if you are getting storage quota exceeded error, create a new service account, and give that service account permission to access the folder and replace the google_credentials.
        gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(
          pkg_resources.resource_filename(__name__, "creds.json"), scopes=['https://www.googleapis.com/auth/drive'])

        drive = GoogleDrive(gauth)

        def upload_file(filepath, folder_id):
            filename = os.path.basename(filepath)
            file = drive.CreateFile({'title': filename, 'parents':[{"id": folder_id}]})
            file.SetContentFile(filepath)
            file.Upload()
            print(f"Uploaded: {filename}")

        for dirpath, dirnames, filenames in os.walk("notebooks"):
            for f in filenames:
                upload_file(os.path.join(dirpath, f), os.environ["TARGET_FOLDER_ID"])
        EOF
